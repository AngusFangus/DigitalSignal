{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io import wavfile as wav #import write\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications  import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento modello per il rilevamento di volti frontali\n",
    "face_detector = cv.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricamento modelli per audio e per video\n",
    "best_model_1 = tf.keras.models.load_model(dir_drive_model + \"best_model\")\n",
    "net = keras.models.load_model('mymodel_64ba.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classi\n",
    "names = ['Marco' ,'Roberto'] #['Marco' ,'Roberto', 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    # Gray scale\n",
    "    f_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # Rilevamento volti\n",
    "    faces = face_detector.detectMultiScale(f_gray) \n",
    "    # Sovrapposizione bounding box con nome all'immagine\n",
    "    for (x,y,w,h) in faces:\n",
    "        # box\n",
    "        cv.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2) \n",
    "        \n",
    "        face = image[y:y+h, x:x+w, :]\n",
    "        img_pixels = cv.resize(face, (224, 224)) \n",
    "        img_pixels = kimage.img_to_array(img_pixels)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels = vgg16.preprocess_input(img_pixels)\n",
    "        y_pred = net.predict(img_pixels)\n",
    "        y_pred_name = np.argmax(y_pred)\n",
    "\n",
    "        cv.putText(image, \n",
    "                   (names[y_pred_name]), #testo\n",
    "                   (x+5,y-5),   #posizione\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, #font\n",
    "                   1.5,         #fontScale\n",
    "                   (255,0,255), #colore\n",
    "                   2)           #spessore\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44000\n",
    "sampling_rate=44000 \n",
    "n_mfcc = 15 \n",
    "\n",
    "eps     = 0.001\n",
    "mean_e  = np.load('mean.npy')\n",
    "std_e   = np.load('std.npy')\n",
    "\n",
    "def extr_feat(sound_clip):\n",
    "    # Mel Frequency Cepstral Coefficents\n",
    "    mfcc = librosa.feature.mfcc(y=sound_clip, sr=sampling_rate,n_mfcc=n_mfcc)\n",
    "            \n",
    "    # MFCC deltas\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "  \n",
    "    # MFCC double deltas\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "  \n",
    "    mel_spectogram = librosa.feature.melspectrogram(y=sound_clip, sr=sampling_rate)\n",
    "    # Root Mean Square Energy\n",
    "    rmse = librosa.feature.rmse(S=mel_spectogram)\n",
    "  \n",
    "    mfcc = np.asarray(mfcc)\n",
    "    mfcc_delta = np.asarray(mfcc_delta)\n",
    "    mfcc_delta2 = np.asarray(mfcc_delta2)\n",
    "    rmse = np.asarray(rmse)\n",
    "\n",
    "    feature = np.concatenate((mfcc, mfcc_delta, mfcc_delta2, rmse), axis=0).T\n",
    "    feature = np.asarray(feature)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap     = cv.VideoCapture(0)\n",
    "seconds = 3 \n",
    "fs      = 44100\n",
    "sent    ='Premere \"r\" per riconoscere chi sta parlando'\n",
    "cv.startWindowThread()\n",
    "\n",
    "while(True):\n",
    "    r, frame = cap.read()\n",
    "    frame = process_frame(frame)\n",
    "    cv.putText(frame, sent, (15, 37), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 1)  \n",
    "    cv.rectangle(frame, (1, 1), (850, 45), (255,255,255), 2)\n",
    "    cv.imshow('Video', frame)\n",
    "    \n",
    "    if cv.waitKey(20) & 0xFF == ord('r'):\n",
    "        prova = sd.rec(int(seconds * fs), samplerate=fs, channels=1, blocking=True)\n",
    "        wav.write('test.wav', rate=fs, data=(prova))\n",
    "        _, rec = wav.read('test.wav')\n",
    "        \n",
    "        feature = extr_feat(rec)\n",
    "        feature = np.array([row for row in (feature - mean_e[0:258] + eps)/(std_e[0:258] + eps)])\n",
    "        feature = feature.reshape(1, feature.shape[0], feature.shape[1])\n",
    "        \n",
    "        prob_audio = best_model_1.predict(feature)\n",
    "        pred_audio = np.argmax(prob_audio)\n",
    "        \n",
    "        if   pred_audio == 0:\n",
    "            res = \"Roberto\"\n",
    "\n",
    "        elif pred_audio == 1:\n",
    "            res = \"Marco\"\n",
    "\n",
    "        elif pred_audio == 2:\n",
    "            res = \"Sconosciuto\"\n",
    "\n",
    "        else:\n",
    "            res =\"Retry\"\n",
    "\n",
    "        sent = 'Ha parlato '+str(res)+' '+str(prob_audio[0][pred_audio])\n",
    "\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
